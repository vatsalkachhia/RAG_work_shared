
# API Contracts

## 1. Chat Endpoint

**Endpoint**  


POST /api/chat



**Description**  
Allows a user to chat with the system.  

- **Before ingestion** → responds using default LLM (general chat).  
- **After ingestion** → responds grounded on ingested document context.  
- Supports runtime configuration (LLM provider, memory type, etc.).  



### Request (JSON)
```json
{
  "session_id": "string", 
  "query": "string",
  "options": {
    "llm_provider": "openai | anthropic | local",
    "llm_model": "gpt-4 | gpt-3.5 | llama-2",
    "memory": {
      "type": "sliding_window | summary",
      "window_size": 5
    }
  }
}
````

* **session\_id**: Used to maintain continuity of chat.
* **query**: User’s chat content.
* **options** *(optional)*: Allows dynamic switching of provider, LLM model, and memory type.

---

### Response (JSON)

```json
{
  "session_id": "string",
  "query": "string",
  "response": "string",
  "metadata": {
    "llm_provider": "openai",
    "llm_model": "gpt-4",
    "memory_type": "sliding_window",
    "source_context": ["doc_chunk_123", "doc_chunk_456"] 
  }
}
```

* **response**: Answer generated by the LLM.
* **metadata**: Confirms which settings were used and, if ingestion is active, the document chunks that supported the answer.

---

## 2. Upload / Ingestion Endpoint

**Endpoint**

```
POST /api/ingest
```

**Description**
Handles document ingestion for retrieval-augmented chat.

* Allows configuration of embeddings, chunking, and vector database selection.

---

### Request (JSON + Multipart/File Upload)

```json
{
  "session_id": "string",
  "document": "base64 or file upload reference",
  "options": {
    "embedding_model": "openai-ada | sentence-transformer | instructor-xl",
    "chunking": {
      "method": "fixed | recursive",
      "chunk_size": 500,
      "overlap": 50
    },
    "vector_db": "pinecone | weaviate | faiss"
  }
}
```

* **session\_id**: Maps the document ingestion to a chat session.
* **document**: File contents (as Base64 or reference to uploaded file).
* **options**: Controls embeddings, chunking strategy, and vector DB.

---

### Response (JSON)

```json
{
  "session_id": "string",
  "status": "success",
  "document_id": "string",
  "metadata": {
    "embedding_model": "sentence-transformer",
    "chunking_method": "fixed",
    "vector_db": "faiss",
    "total_chunks": 42
  }
}
```

* **status**: Indicates if ingestion succeeded.
* **document\_id**: Unique reference to the ingested document.
* **metadata**: Confirms settings used and ingestion statistics.

```
```
